{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "name": "labtask12.ipynb",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/hikmat690/AI-programming/blob/main/labtask12.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **Sentiment Analysis (Text Classification)**\n",
        "*   **Downloading Datset from Kaggle to Google Colab**\n",
        "*   **Text Cleaning**\n",
        "*   **Text Preprocessing**\n",
        "*   **Feature Engineering**\n",
        "*   **ML Model**"
      ],
      "metadata": {
        "id": "QKxILf5ndoUD"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "NmKnCfBodcue",
        "outputId": "f02a2859-760d-441d-8bc1-bf6e9d44374f"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: kaggle in /usr/local/lib/python3.10/dist-packages (1.6.17)\n",
            "Requirement already satisfied: six>=1.10 in /usr/local/lib/python3.10/dist-packages (from kaggle) (1.16.0)\n",
            "Requirement already satisfied: certifi>=2023.7.22 in /usr/local/lib/python3.10/dist-packages (from kaggle) (2024.8.30)\n",
            "Requirement already satisfied: python-dateutil in /usr/local/lib/python3.10/dist-packages (from kaggle) (2.8.2)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.10/dist-packages (from kaggle) (2.32.3)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.10/dist-packages (from kaggle) (4.66.6)\n",
            "Requirement already satisfied: python-slugify in /usr/local/lib/python3.10/dist-packages (from kaggle) (8.0.4)\n",
            "Requirement already satisfied: urllib3 in /usr/local/lib/python3.10/dist-packages (from kaggle) (2.2.3)\n",
            "Requirement already satisfied: bleach in /usr/local/lib/python3.10/dist-packages (from kaggle) (6.2.0)\n",
            "Requirement already satisfied: webencodings in /usr/local/lib/python3.10/dist-packages (from bleach->kaggle) (0.5.1)\n",
            "Requirement already satisfied: text-unidecode>=1.3 in /usr/local/lib/python3.10/dist-packages (from python-slugify->kaggle) (1.3)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests->kaggle) (3.4.0)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests->kaggle) (3.10)\n",
            "Dataset URL: https://www.kaggle.com/datasets/lakshmi25npathi/imdb-dataset-of-50k-movie-reviews\n",
            "License(s): other\n",
            "Downloading imdb-dataset-of-50k-movie-reviews.zip to /content\n",
            " 86% 22.0M/25.7M [00:01<00:00, 23.2MB/s]\n",
            "100% 25.7M/25.7M [00:01<00:00, 17.0MB/s]\n",
            "Archive:  imdb-dataset-of-50k-movie-reviews.zip\n",
            "  inflating: IMDB Dataset.csv        \n"
          ]
        }
      ],
      "source": [
        "#!/bin/bash\n",
        "!pip install kaggle\n",
        "\n",
        "import os\n",
        "import json\n",
        "\n",
        "# Set up Kaggle API credentials\n",
        "#os.environ['KAGGLE_CONFIG_DIR'] = \"/content\"\n",
        "#/content/kaggle.json\n",
        "# Make the Kaggle API key available to the environment\n",
        "with open('/content/kaggle.json') as f:\n",
        "    kaggle_json = json.load(f)\n",
        "    os.environ['KAGGLE_USERNAME'] = kaggle_json['username']\n",
        "    os.environ['KAGGLE_KEY'] = kaggle_json['key']\n",
        "\n",
        "#!/bin/bash\n",
        "!kaggle datasets download lakshmi25npathi/imdb-dataset-of-50k-movie-reviews\n",
        "\n",
        "!unzip imdb-dataset-of-50k-movie-reviews.zip"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **Importing Preprocessing Libraries**"
      ],
      "metadata": {
        "id": "Opp1GMraebjN"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import string\n",
        "\n",
        "\n",
        "import re\n",
        "import nltk\n",
        "from nltk.tokenize import word_tokenize\n",
        "from nltk.corpus import stopwords\n",
        "from nltk.stem import WordNetLemmatizer\n",
        "\n",
        "\n",
        "nltk.download('wordnet')\n",
        "nltk.download('stopwords')\n",
        "nltk.download('punkt_tab')\n",
        "\n",
        "\n",
        "stopwords.words('english')\n",
        "exclude = string.punctuation"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "S5-bcmcNee4l",
        "outputId": "92f7ba37-953d-4306-fa42-4916fd3b7ba4"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[nltk_data] Downloading package wordnet to /root/nltk_data...\n",
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Unzipping corpora/stopwords.zip.\n",
            "[nltk_data] Downloading package punkt_tab to /root/nltk_data...\n",
            "[nltk_data]   Unzipping tokenizers/punkt_tab.zip.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **Reading Data**"
      ],
      "metadata": {
        "id": "A4QQYCBbeonO"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "temp_df = pd.read_csv('/content/IMDB Dataset.csv')\n",
        "df = temp_df.iloc[:30000]"
      ],
      "metadata": {
        "id": "IT9OMIfMe0jm"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **Text Cleaning & Preprocessing**"
      ],
      "metadata": {
        "id": "KkZ1tUgelQgI"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def remove_html_tags(text):\n",
        "    pattern = re.compile('<.*?>')\n",
        "    return pattern.sub(r'', text)\n",
        "\n",
        "def remove_url(text):\n",
        "    pattern = re.compile(r'https?://\\S+|www\\.\\S+')\n",
        "    return pattern.sub(r'', text)\n",
        "\n",
        "#exclude = \"!.,?\"\n",
        "def remove_punc(text):\n",
        "    return text.translate(str.maketrans('', '', exclude))"
      ],
      "metadata": {
        "id": "1pKTCdM-e9ul"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df['review'] = df['review'].str.lower()\n",
        "\n",
        "df['review'] = df['review'].apply(remove_html_tags)\n",
        "\n",
        "df['review'] = df['review'].apply(remove_url)\n",
        "\n",
        "df['review'] = df['review'].apply(remove_punc)\n",
        "\n",
        "#df['review'] = df['review'].apply(word_tokenize)\n",
        "\n",
        "#df['review'] = df['review'].apply(remove_stopwords)\n",
        "\n",
        "#df['review'] = df['review'].apply(lemmatize_words)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "gMJGFEx7kbKF",
        "outputId": "c2a2df36-7135-49fe-b401-67f17d1a09cf"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-5-6f636dc7a57c>:1: SettingWithCopyWarning: \n",
            "A value is trying to be set on a copy of a slice from a DataFrame.\n",
            "Try using .loc[row_indexer,col_indexer] = value instead\n",
            "\n",
            "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
            "  df['review'] = df['review'].str.lower()\n",
            "<ipython-input-5-6f636dc7a57c>:3: SettingWithCopyWarning: \n",
            "A value is trying to be set on a copy of a slice from a DataFrame.\n",
            "Try using .loc[row_indexer,col_indexer] = value instead\n",
            "\n",
            "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
            "  df['review'] = df['review'].apply(remove_html_tags)\n",
            "<ipython-input-5-6f636dc7a57c>:5: SettingWithCopyWarning: \n",
            "A value is trying to be set on a copy of a slice from a DataFrame.\n",
            "Try using .loc[row_indexer,col_indexer] = value instead\n",
            "\n",
            "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
            "  df['review'] = df['review'].apply(remove_url)\n",
            "<ipython-input-5-6f636dc7a57c>:7: SettingWithCopyWarning: \n",
            "A value is trying to be set on a copy of a slice from a DataFrame.\n",
            "Try using .loc[row_indexer,col_indexer] = value instead\n",
            "\n",
            "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
            "  df['review'] = df['review'].apply(remove_punc)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **Tokenization Function**"
      ],
      "metadata": {
        "id": "2QTuG3YEz-SX"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def tokenize_reviews(df):\n",
        "    df['tokenized_reviews'] = df['review'].apply(word_tokenize)\n",
        "    return df\n",
        "\n",
        "# Apply tokenization\n",
        "df = tokenize_reviews(df)\n",
        "print(\"Tokenization completed.\")\n",
        "print(df[['review', 'tokenized_reviews']].head())\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "NeD683-7z7uh",
        "outputId": "1e2e379a-0cfa-4202-fd82-59fb05ba5906"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Tokenization completed.\n",
            "                                              review  \\\n",
            "0  one of the other reviewers has mentioned that ...   \n",
            "1  a wonderful little production the filming tech...   \n",
            "2  i thought this was a wonderful way to spend ti...   \n",
            "3  basically theres a family where a little boy j...   \n",
            "4  petter matteis love in the time of money is a ...   \n",
            "\n",
            "                                   tokenized_reviews  \n",
            "0  [one, of, the, other, reviewers, has, mentione...  \n",
            "1  [a, wonderful, little, production, the, filmin...  \n",
            "2  [i, thought, this, was, a, wonderful, way, to,...  \n",
            "3  [basically, theres, a, family, where, a, littl...  \n",
            "4  [petter, matteis, love, in, the, time, of, mon...  \n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-6-c120d2b48c1c>:2: SettingWithCopyWarning: \n",
            "A value is trying to be set on a copy of a slice from a DataFrame.\n",
            "Try using .loc[row_indexer,col_indexer] = value instead\n",
            "\n",
            "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
            "  df['tokenized_reviews'] = df['review'].apply(word_tokenize)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **Stopword Removal Function**"
      ],
      "metadata": {
        "id": "T1-GXy8z0K_Q"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def remove_stopwords(df):\n",
        "    stop_words = set(stopwords.words('english'))\n",
        "    df['cleaned_reviews'] = df['tokenized_reviews'].apply(\n",
        "        lambda tokens: [word for word in tokens if word.lower() not in stop_words]\n",
        "    )\n",
        "    return df\n",
        "\n",
        "# Apply stopword removal\n",
        "df = remove_stopwords(df)\n",
        "print(\"Stopword removal completed.\")\n",
        "print(df[['review', 'cleaned_reviews']].head())\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "S0nfI6YA0KIB",
        "outputId": "1b29d964-7425-425a-a43e-0c23aa0ace0d"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Stopword removal completed.\n",
            "                                              review  \\\n",
            "0  one of the other reviewers has mentioned that ...   \n",
            "1  a wonderful little production the filming tech...   \n",
            "2  i thought this was a wonderful way to spend ti...   \n",
            "3  basically theres a family where a little boy j...   \n",
            "4  petter matteis love in the time of money is a ...   \n",
            "\n",
            "                                     cleaned_reviews  \n",
            "0  [one, reviewers, mentioned, watching, 1, oz, e...  \n",
            "1  [wonderful, little, production, filming, techn...  \n",
            "2  [thought, wonderful, way, spend, time, hot, su...  \n",
            "3  [basically, theres, family, little, boy, jake,...  \n",
            "4  [petter, matteis, love, time, money, visually,...  \n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-7-8ddce2b8c724>:3: SettingWithCopyWarning: \n",
            "A value is trying to be set on a copy of a slice from a DataFrame.\n",
            "Try using .loc[row_indexer,col_indexer] = value instead\n",
            "\n",
            "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
            "  df['cleaned_reviews'] = df['tokenized_reviews'].apply(\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **Lemmatization Function**"
      ],
      "metadata": {
        "id": "cscO5wpl0Y0s"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def lemmatize_reviews(df):\n",
        "    lemmatizer = WordNetLemmatizer()\n",
        "    df['lemmatized_reviews'] = df['cleaned_reviews'].apply(\n",
        "        lambda tokens: [lemmatizer.lemmatize(word) for word in tokens]\n",
        "    )\n",
        "    return df\n",
        "\n",
        "# Apply lemmatization\n",
        "df = lemmatize_reviews(df)\n",
        "print(\"Lemmatization completed.\")\n",
        "print(df[['review', 'lemmatized_reviews']].head())\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "e-WxYnOp0d2r",
        "outputId": "48402960-09d3-4ad2-81cc-0023c778e390"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Lemmatization completed.\n",
            "                                              review  \\\n",
            "0  one of the other reviewers has mentioned that ...   \n",
            "1  a wonderful little production the filming tech...   \n",
            "2  i thought this was a wonderful way to spend ti...   \n",
            "3  basically theres a family where a little boy j...   \n",
            "4  petter matteis love in the time of money is a ...   \n",
            "\n",
            "                                  lemmatized_reviews  \n",
            "0  [one, reviewer, mentioned, watching, 1, oz, ep...  \n",
            "1  [wonderful, little, production, filming, techn...  \n",
            "2  [thought, wonderful, way, spend, time, hot, su...  \n",
            "3  [basically, there, family, little, boy, jake, ...  \n",
            "4  [petter, matteis, love, time, money, visually,...  \n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-8-81a4c4ce13f1>:3: SettingWithCopyWarning: \n",
            "A value is trying to be set on a copy of a slice from a DataFrame.\n",
            "Try using .loc[row_indexer,col_indexer] = value instead\n",
            "\n",
            "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
            "  df['lemmatized_reviews'] = df['cleaned_reviews'].apply(\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **Feature Engineering**"
      ],
      "metadata": {
        "id": "zV6bPViYl3_Q"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Target Column Encoding**"
      ],
      "metadata": {
        "id": "JJozhru2MDY_"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.preprocessing import LabelEncoder\n",
        "\n",
        "#X = df.drop('sentiment', axis=1)\n",
        "X = df['review']\n",
        "Y = df['sentiment']\n",
        "\n",
        "print(X)\n",
        "print(Y)\n",
        "\n",
        "encoder = LabelEncoder()\n",
        "Y = encoder.fit_transform(Y)\n",
        "\n",
        "print(Y)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ZuTETTE2Retv",
        "outputId": "153ad8ec-ed8c-400b-e7be-fd4e5acc0111"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "0        one of the other reviewers has mentioned that ...\n",
            "1        a wonderful little production the filming tech...\n",
            "2        i thought this was a wonderful way to spend ti...\n",
            "3        basically theres a family where a little boy j...\n",
            "4        petter matteis love in the time of money is a ...\n",
            "                               ...                        \n",
            "29995    new york i love you finally makes it to our sh...\n",
            "29996    this movie makes you wish imdb would let you v...\n",
            "29997    space camp which had the unfortunate luck to b...\n",
            "29998    octavio paz mexican poet writer and diplomat w...\n",
            "29999    having watched 10 minutes of this movie i was ...\n",
            "Name: review, Length: 30000, dtype: object\n",
            "0        positive\n",
            "1        positive\n",
            "2        positive\n",
            "3        negative\n",
            "4        positive\n",
            "           ...   \n",
            "29995    positive\n",
            "29996    negative\n",
            "29997    negative\n",
            "29998    positive\n",
            "29999    negative\n",
            "Name: sentiment, Length: 30000, dtype: object\n",
            "[1 1 1 ... 0 1 0]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Bag of Words**"
      ],
      "metadata": {
        "id": "S7enK_qOl9Mi"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.feature_extraction.text import CountVectorizer\n",
        "from sklearn.ensemble import RandomForestClassifier\n",
        "from sklearn.metrics import accuracy_score,confusion_matrix\n",
        "\n",
        "X_train,X_test,y_train,y_test = train_test_split(X,Y,test_size=0.2,random_state=42)\n",
        "\n",
        "print(X_train.shape)\n",
        "#print(X_train.head)\n",
        "\n",
        "#print(X_train)\n",
        "#print(X_test)\n",
        "\n",
        "# Initialize the CountVectorizer\n",
        "vectorizer = CountVectorizer()\n",
        "\n",
        "# Fit the vectorizer on the training data and transform it\n",
        "X_train_bow = vectorizer.fit_transform(X_train)\n",
        "\n",
        "# Transform the test data using the same vectorizer\n",
        "X_test_bow = vectorizer.transform(X_test)\n",
        "\n",
        "# Output the shapes of the resulting Bag of Words matrices\n",
        "print(f\"Shape of X_train_bow: {X_train_bow.shape}\")\n",
        "print(f\"Shape of X_test_bow: {X_test_bow.shape}\")\n",
        "\n",
        "# Applying Random Forest Classifier\n",
        "rf = RandomForestClassifier()\n",
        "\n",
        "rf.fit(X_train_bow,y_train)\n",
        "y_pred = rf.predict(X_test_bow)\n",
        "#accuracy_score(y_test,y_pred)\n",
        "\n",
        "print (accuracy_score(y_test,y_pred))\n",
        "print (confusion_matrix(y_test,y_pred))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "hu52GS7sSEbM",
        "outputId": "e645fdeb-b232-4255-ea66-aeb9cc2270a4"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(24000,)\n",
            "Shape of X_train_bow: (24000, 139736)\n",
            "Shape of X_test_bow: (6000, 139736)\n",
            "0.849\n",
            "[[2554  475]\n",
            " [ 431 2540]]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "84.8 to 84.9"
      ],
      "metadata": {
        "id": "QCh0jHNn1qhJ"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**n-gram (2-gram)**"
      ],
      "metadata": {
        "id": "J1sjksiJMUIi"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "cv = CountVectorizer(ngram_range=(2,2))\n",
        "\n",
        "X_train_n_gram = cv.fit_transform(X_train)\n",
        "X_test_n_gram = cv.transform(X_test)\n",
        "\n",
        "# Output the shapes of the resulting Bag of Words matrices\n",
        "print(f\"Shape of X_train_bow: {X_train_n_gram.shape}\")\n",
        "print(f\"Shape of X_test_bow: {X_test_n_gram.shape}\")\n",
        "\n",
        "rf = RandomForestClassifier()\n",
        "\n",
        "rf.fit(X_train_n_gram,y_train)\n",
        "y_pred = rf.predict(X_test_n_gram)\n",
        "\n",
        "print (accuracy_score(y_test,y_pred))\n",
        "print (confusion_matrix(y_test,y_pred))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0m0KGuBSNatZ",
        "outputId": "eaeb1651-785b-42d8-c034-4e962d43ce1b"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Shape of X_train_bow: (24000, 1500023)\n",
            "Shape of X_test_bow: (6000, 1500023)\n",
            "0.8328333333333333\n",
            "[[2477  552]\n",
            " [ 451 2520]]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "84.5 to 83.3"
      ],
      "metadata": {
        "id": "k4PIUMn-4ta8"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**TF/IDF**"
      ],
      "metadata": {
        "id": "4QsY7r2INm7d"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.feature_extraction.text import TfidfVectorizer\n",
        "tfidf = TfidfVectorizer()\n",
        "\n",
        "X_train_tfidf = tfidf.fit_transform(X_train)\n",
        "X_test_tfidf = tfidf.transform(X_test)\n",
        "\n",
        "# Output the shapes of the resulting Bag of Words matrices\n",
        "print(f\"Shape of X_train_bow: {X_train_tfidf.shape}\")\n",
        "print(f\"Shape of X_test_bow: {X_test_tfidf.shape}\")\n",
        "\n",
        "rf = RandomForestClassifier()\n",
        "\n",
        "rf.fit(X_train_tfidf,y_train)\n",
        "y_pred = rf.predict(X_test_tfidf)\n",
        "\n",
        "print (accuracy_score(y_test,y_pred))\n",
        "print (confusion_matrix(y_test,y_pred))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "WQNLOLLyNr2v",
        "outputId": "fe6c21eb-1a20-4c10-9416-58fa99d286b9"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Shape of X_train_bow: (24000, 139736)\n",
            "Shape of X_test_bow: (6000, 139736)\n",
            "0.8361666666666666\n",
            "[[2549  480]\n",
            " [ 503 2468]]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "83.35 to 83.61"
      ],
      "metadata": {
        "id": "5uDPndvY5PLx"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **Task:**\n",
        "*   **Add a Python Function for Word-based Tokenization for each of the IMDB reviews data.**\n",
        "*   **After tokenization, add a Python Function to remove Stop Words from the IMDB reviews data.**\n",
        "*   **After Stopword Removal, add a Python Function to perform Lemmitization over IMDB Reviews data.**\n",
        "\n",
        "**After applying the above mentioned data preprocessing steps, again run this code and analyse the performance of the ML models for text classification of IMDB Reviews.**\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "xbqQjfUg4PG3"
      }
    }
  ]
}