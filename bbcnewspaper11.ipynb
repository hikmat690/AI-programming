{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyOJ/tiWc7zWI/kw9VvD1q40",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/hikmat690/AI-programming/blob/main/bbcnewspaper11.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **Sentiment Analysis (Text Classification)**\n",
        "*   **Downloading Datset from Kaggle to Google Colab**\n",
        "*   **Text Cleaning**\n",
        "*   **BERT Model (Feature Engineering)**\n",
        "*   **DL Model**"
      ],
      "metadata": {
        "id": "QKxILf5ndoUD"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **Importing Preprocessing Libraries**"
      ],
      "metadata": {
        "id": "Opp1GMraebjN"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install -U \"tensorflow-text==2.13.*\""
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "CGrfHJPzwA8y",
        "outputId": "96900535-2bd3-4e45-b733-2599fc9853ac"
      },
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting tensorflow-text==2.13.*\n",
            "  Downloading tensorflow_text-2.13.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (2.0 kB)\n",
            "Requirement already satisfied: tensorflow-hub>=0.8.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow-text==2.13.*) (0.16.1)\n",
            "Collecting tensorflow<2.14,>=2.13.0 (from tensorflow-text==2.13.*)\n",
            "  Downloading tensorflow-2.13.1-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (3.4 kB)\n",
            "Requirement already satisfied: absl-py>=1.0.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow<2.14,>=2.13.0->tensorflow-text==2.13.*) (1.4.0)\n",
            "Requirement already satisfied: astunparse>=1.6.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow<2.14,>=2.13.0->tensorflow-text==2.13.*) (1.6.3)\n",
            "Requirement already satisfied: flatbuffers>=23.1.21 in /usr/local/lib/python3.10/dist-packages (from tensorflow<2.14,>=2.13.0->tensorflow-text==2.13.*) (24.3.25)\n",
            "Collecting gast<=0.4.0,>=0.2.1 (from tensorflow<2.14,>=2.13.0->tensorflow-text==2.13.*)\n",
            "  Downloading gast-0.4.0-py3-none-any.whl.metadata (1.1 kB)\n",
            "Requirement already satisfied: google-pasta>=0.1.1 in /usr/local/lib/python3.10/dist-packages (from tensorflow<2.14,>=2.13.0->tensorflow-text==2.13.*) (0.2.0)\n",
            "Requirement already satisfied: grpcio<2.0,>=1.24.3 in /usr/local/lib/python3.10/dist-packages (from tensorflow<2.14,>=2.13.0->tensorflow-text==2.13.*) (1.68.1)\n",
            "Requirement already satisfied: h5py>=2.9.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow<2.14,>=2.13.0->tensorflow-text==2.13.*) (3.12.1)\n",
            "Collecting keras<2.14,>=2.13.1 (from tensorflow<2.14,>=2.13.0->tensorflow-text==2.13.*)\n",
            "  Downloading keras-2.13.1-py3-none-any.whl.metadata (2.4 kB)\n",
            "Requirement already satisfied: libclang>=13.0.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow<2.14,>=2.13.0->tensorflow-text==2.13.*) (18.1.1)\n",
            "Collecting numpy<=1.24.3,>=1.22 (from tensorflow<2.14,>=2.13.0->tensorflow-text==2.13.*)\n",
            "  Downloading numpy-1.24.3-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (5.6 kB)\n",
            "Requirement already satisfied: opt-einsum>=2.3.2 in /usr/local/lib/python3.10/dist-packages (from tensorflow<2.14,>=2.13.0->tensorflow-text==2.13.*) (3.4.0)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.10/dist-packages (from tensorflow<2.14,>=2.13.0->tensorflow-text==2.13.*) (24.2)\n",
            "Requirement already satisfied: protobuf!=4.21.0,!=4.21.1,!=4.21.2,!=4.21.3,!=4.21.4,!=4.21.5,<5.0.0dev,>=3.20.3 in /usr/local/lib/python3.10/dist-packages (from tensorflow<2.14,>=2.13.0->tensorflow-text==2.13.*) (4.25.5)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.10/dist-packages (from tensorflow<2.14,>=2.13.0->tensorflow-text==2.13.*) (75.1.0)\n",
            "Requirement already satisfied: six>=1.12.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow<2.14,>=2.13.0->tensorflow-text==2.13.*) (1.17.0)\n",
            "Collecting tensorboard<2.14,>=2.13 (from tensorflow<2.14,>=2.13.0->tensorflow-text==2.13.*)\n",
            "  Downloading tensorboard-2.13.0-py3-none-any.whl.metadata (1.8 kB)\n",
            "Collecting tensorflow-estimator<2.14,>=2.13.0 (from tensorflow<2.14,>=2.13.0->tensorflow-text==2.13.*)\n",
            "  Downloading tensorflow_estimator-2.13.0-py2.py3-none-any.whl.metadata (1.3 kB)\n",
            "Requirement already satisfied: termcolor>=1.1.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow<2.14,>=2.13.0->tensorflow-text==2.13.*) (2.5.0)\n",
            "Collecting typing-extensions<4.6.0,>=3.6.6 (from tensorflow<2.14,>=2.13.0->tensorflow-text==2.13.*)\n",
            "  Downloading typing_extensions-4.5.0-py3-none-any.whl.metadata (8.5 kB)\n",
            "Requirement already satisfied: wrapt>=1.11.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow<2.14,>=2.13.0->tensorflow-text==2.13.*) (1.17.0)\n",
            "Requirement already satisfied: tensorflow-io-gcs-filesystem>=0.23.1 in /usr/local/lib/python3.10/dist-packages (from tensorflow<2.14,>=2.13.0->tensorflow-text==2.13.*) (0.37.1)\n",
            "Requirement already satisfied: tf-keras>=2.14.1 in /usr/local/lib/python3.10/dist-packages (from tensorflow-hub>=0.8.0->tensorflow-text==2.13.*) (2.17.0)\n",
            "Requirement already satisfied: wheel<1.0,>=0.23.0 in /usr/local/lib/python3.10/dist-packages (from astunparse>=1.6.0->tensorflow<2.14,>=2.13.0->tensorflow-text==2.13.*) (0.45.1)\n",
            "Requirement already satisfied: google-auth<3,>=1.6.3 in /usr/local/lib/python3.10/dist-packages (from tensorboard<2.14,>=2.13->tensorflow<2.14,>=2.13.0->tensorflow-text==2.13.*) (2.27.0)\n",
            "Collecting google-auth-oauthlib<1.1,>=0.5 (from tensorboard<2.14,>=2.13->tensorflow<2.14,>=2.13.0->tensorflow-text==2.13.*)\n",
            "  Downloading google_auth_oauthlib-1.0.0-py2.py3-none-any.whl.metadata (2.7 kB)\n",
            "Requirement already satisfied: markdown>=2.6.8 in /usr/local/lib/python3.10/dist-packages (from tensorboard<2.14,>=2.13->tensorflow<2.14,>=2.13.0->tensorflow-text==2.13.*) (3.7)\n",
            "Requirement already satisfied: requests<3,>=2.21.0 in /usr/local/lib/python3.10/dist-packages (from tensorboard<2.14,>=2.13->tensorflow<2.14,>=2.13.0->tensorflow-text==2.13.*) (2.32.3)\n",
            "Requirement already satisfied: tensorboard-data-server<0.8.0,>=0.7.0 in /usr/local/lib/python3.10/dist-packages (from tensorboard<2.14,>=2.13->tensorflow<2.14,>=2.13.0->tensorflow-text==2.13.*) (0.7.2)\n",
            "Requirement already satisfied: werkzeug>=1.0.1 in /usr/local/lib/python3.10/dist-packages (from tensorboard<2.14,>=2.13->tensorflow<2.14,>=2.13.0->tensorflow-text==2.13.*) (3.1.3)\n",
            "INFO: pip is looking at multiple versions of tf-keras to determine which version is compatible with other requirements. This could take a while.\n",
            "Collecting tf-keras>=2.14.1 (from tensorflow-hub>=0.8.0->tensorflow-text==2.13.*)\n",
            "  Downloading tf_keras-2.18.0-py3-none-any.whl.metadata (1.6 kB)\n",
            "  Downloading tf_keras-2.16.0-py3-none-any.whl.metadata (1.6 kB)\n",
            "  Downloading tf_keras-2.15.1-py3-none-any.whl.metadata (1.7 kB)\n",
            "  Downloading tf_keras-2.15.0-py3-none-any.whl.metadata (1.6 kB)\n",
            "Requirement already satisfied: cachetools<6.0,>=2.0.0 in /usr/local/lib/python3.10/dist-packages (from google-auth<3,>=1.6.3->tensorboard<2.14,>=2.13->tensorflow<2.14,>=2.13.0->tensorflow-text==2.13.*) (5.5.0)\n",
            "Requirement already satisfied: pyasn1-modules>=0.2.1 in /usr/local/lib/python3.10/dist-packages (from google-auth<3,>=1.6.3->tensorboard<2.14,>=2.13->tensorflow<2.14,>=2.13.0->tensorflow-text==2.13.*) (0.4.1)\n",
            "Requirement already satisfied: rsa<5,>=3.1.4 in /usr/local/lib/python3.10/dist-packages (from google-auth<3,>=1.6.3->tensorboard<2.14,>=2.13->tensorflow<2.14,>=2.13.0->tensorflow-text==2.13.*) (4.9)\n",
            "Requirement already satisfied: requests-oauthlib>=0.7.0 in /usr/local/lib/python3.10/dist-packages (from google-auth-oauthlib<1.1,>=0.5->tensorboard<2.14,>=2.13->tensorflow<2.14,>=2.13.0->tensorflow-text==2.13.*) (1.3.1)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2.21.0->tensorboard<2.14,>=2.13->tensorflow<2.14,>=2.13.0->tensorflow-text==2.13.*) (3.4.0)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2.21.0->tensorboard<2.14,>=2.13->tensorflow<2.14,>=2.13.0->tensorflow-text==2.13.*) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2.21.0->tensorboard<2.14,>=2.13->tensorflow<2.14,>=2.13.0->tensorflow-text==2.13.*) (2.2.3)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2.21.0->tensorboard<2.14,>=2.13->tensorflow<2.14,>=2.13.0->tensorflow-text==2.13.*) (2024.12.14)\n",
            "Requirement already satisfied: MarkupSafe>=2.1.1 in /usr/local/lib/python3.10/dist-packages (from werkzeug>=1.0.1->tensorboard<2.14,>=2.13->tensorflow<2.14,>=2.13.0->tensorflow-text==2.13.*) (3.0.2)\n",
            "Requirement already satisfied: pyasn1<0.7.0,>=0.4.6 in /usr/local/lib/python3.10/dist-packages (from pyasn1-modules>=0.2.1->google-auth<3,>=1.6.3->tensorboard<2.14,>=2.13->tensorflow<2.14,>=2.13.0->tensorflow-text==2.13.*) (0.6.1)\n",
            "Requirement already satisfied: oauthlib>=3.0.0 in /usr/local/lib/python3.10/dist-packages (from requests-oauthlib>=0.7.0->google-auth-oauthlib<1.1,>=0.5->tensorboard<2.14,>=2.13->tensorflow<2.14,>=2.13.0->tensorflow-text==2.13.*) (3.2.2)\n",
            "Downloading tensorflow_text-2.13.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (6.5 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m6.5/6.5 MB\u001b[0m \u001b[31m22.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading tensorflow-2.13.1-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (479.7 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m479.7/479.7 MB\u001b[0m \u001b[31m3.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading gast-0.4.0-py3-none-any.whl (9.8 kB)\n",
            "Downloading keras-2.13.1-py3-none-any.whl (1.7 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.7/1.7 MB\u001b[0m \u001b[31m20.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading numpy-1.24.3-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (17.3 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m17.3/17.3 MB\u001b[0m \u001b[31m25.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading tensorboard-2.13.0-py3-none-any.whl (5.6 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m5.6/5.6 MB\u001b[0m \u001b[31m14.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading tensorflow_estimator-2.13.0-py2.py3-none-any.whl (440 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m440.8/440.8 kB\u001b[0m \u001b[31m16.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading tf_keras-2.15.0-py3-none-any.whl (1.7 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.7/1.7 MB\u001b[0m \u001b[31m15.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading typing_extensions-4.5.0-py3-none-any.whl (27 kB)\n",
            "Downloading google_auth_oauthlib-1.0.0-py2.py3-none-any.whl (18 kB)\n",
            "Installing collected packages: typing-extensions, tf-keras, tensorflow-estimator, numpy, keras, gast, google-auth-oauthlib, tensorboard, tensorflow, tensorflow-text\n",
            "  Attempting uninstall: typing-extensions\n",
            "    Found existing installation: typing_extensions 4.12.2\n",
            "    Uninstalling typing_extensions-4.12.2:\n",
            "      Successfully uninstalled typing_extensions-4.12.2\n",
            "  Attempting uninstall: tf-keras\n",
            "    Found existing installation: tf_keras 2.17.0\n",
            "    Uninstalling tf_keras-2.17.0:\n",
            "      Successfully uninstalled tf_keras-2.17.0\n",
            "  Attempting uninstall: numpy\n",
            "    Found existing installation: numpy 1.26.4\n",
            "    Uninstalling numpy-1.26.4:\n",
            "      Successfully uninstalled numpy-1.26.4\n",
            "  Attempting uninstall: keras\n",
            "    Found existing installation: keras 3.5.0\n",
            "    Uninstalling keras-3.5.0:\n",
            "      Successfully uninstalled keras-3.5.0\n",
            "  Attempting uninstall: gast\n",
            "    Found existing installation: gast 0.6.0\n",
            "    Uninstalling gast-0.6.0:\n",
            "      Successfully uninstalled gast-0.6.0\n",
            "  Attempting uninstall: google-auth-oauthlib\n",
            "    Found existing installation: google-auth-oauthlib 1.2.1\n",
            "    Uninstalling google-auth-oauthlib-1.2.1:\n",
            "      Successfully uninstalled google-auth-oauthlib-1.2.1\n",
            "  Attempting uninstall: tensorboard\n",
            "    Found existing installation: tensorboard 2.17.1\n",
            "    Uninstalling tensorboard-2.17.1:\n",
            "      Successfully uninstalled tensorboard-2.17.1\n",
            "  Attempting uninstall: tensorflow\n",
            "    Found existing installation: tensorflow 2.17.1\n",
            "    Uninstalling tensorflow-2.17.1:\n",
            "      Successfully uninstalled tensorflow-2.17.1\n",
            "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
            "sqlalchemy 2.0.36 requires typing-extensions>=4.6.0, but you have typing-extensions 4.5.0 which is incompatible.\n",
            "albucore 0.0.19 requires numpy>=1.24.4, but you have numpy 1.24.3 which is incompatible.\n",
            "albumentations 1.4.20 requires numpy>=1.24.4, but you have numpy 1.24.3 which is incompatible.\n",
            "altair 5.5.0 requires typing-extensions>=4.10.0; python_version < \"3.14\", but you have typing-extensions 4.5.0 which is incompatible.\n",
            "langchain-core 0.3.25 requires typing-extensions>=4.7, but you have typing-extensions 4.5.0 which is incompatible.\n",
            "nibabel 5.3.2 requires typing-extensions>=4.6; python_version < \"3.13\", but you have typing-extensions 4.5.0 which is incompatible.\n",
            "openai 1.57.4 requires typing-extensions<5,>=4.11, but you have typing-extensions 4.5.0 which is incompatible.\n",
            "pydantic 2.10.3 requires typing-extensions>=4.12.2, but you have typing-extensions 4.5.0 which is incompatible.\n",
            "pydantic-core 2.27.1 requires typing-extensions!=4.7.0,>=4.6.0, but you have typing-extensions 4.5.0 which is incompatible.\n",
            "pymc 5.19.1 requires numpy>=1.25.0, but you have numpy 1.24.3 which is incompatible.\n",
            "torch 2.5.1+cu121 requires typing-extensions>=4.8.0, but you have typing-extensions 4.5.0 which is incompatible.\n",
            "typeguard 4.4.1 requires typing-extensions>=4.10.0, but you have typing-extensions 4.5.0 which is incompatible.\u001b[0m\u001b[31m\n",
            "\u001b[0mSuccessfully installed gast-0.4.0 google-auth-oauthlib-1.0.0 keras-2.13.1 numpy-1.24.3 tensorboard-2.13.0 tensorflow-2.13.1 tensorflow-estimator-2.13.0 tensorflow-text-2.13.0 tf-keras-2.15.0 typing-extensions-4.5.0\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.colab-display-data+json": {
              "pip_warning": {
                "packages": [
                  "numpy"
                ]
              },
              "id": "58e2c6bfc7ad4bbaa2de738f8095b3b4"
            }
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#!pip install --quiet tensorflow_text\n",
        "\n",
        "import re\n",
        "import nltk\n",
        "import string\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.feature_extraction.text import CountVectorizer\n",
        "from sklearn.ensemble import RandomForestClassifier\n",
        "from sklearn.metrics import f1_score,precision_score,accuracy_score,confusion_matrix\n",
        "\n",
        "import pandas as pd\n",
        "import tensorflow as tf\n",
        "import tensorflow_hub as hub\n",
        "import tensorflow_text as text\n",
        "from nltk.corpus import stopwords\n",
        "\n",
        "nltk.download('wordnet')\n",
        "nltk.download('stopwords')\n",
        "nltk.download('punkt_tab')\n",
        "\n",
        "\n",
        "stopwords.words('english')\n",
        "exclude = string.punctuation"
      ],
      "metadata": {
        "id": "S5-bcmcNee4l",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "1bbb19df-5679-4e83-bf88-937519442060"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[nltk_data] Downloading package wordnet to /root/nltk_data...\n",
            "[nltk_data]   Package wordnet is already up-to-date!\n",
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Package stopwords is already up-to-date!\n",
            "[nltk_data] Downloading package punkt_tab to /root/nltk_data...\n",
            "[nltk_data]   Package punkt_tab is already up-to-date!\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **Reading Data**"
      ],
      "metadata": {
        "id": "A4QQYCBbeonO"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "temp_df = pd.read_csv('/content/bbc-text.csv')\n",
        "df = temp_df.iloc[:100]"
      ],
      "metadata": {
        "id": "IT9OMIfMe0jm"
      },
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df.shape"
      ],
      "metadata": {
        "id": "oBxAIuO7VL3M",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "2fd587b8-1014-4e1f-dcfe-5f2ea1ed9b10"
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(100, 2)"
            ]
          },
          "metadata": {},
          "execution_count": 8
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **Text Cleaning & Preprocessing**"
      ],
      "metadata": {
        "id": "KkZ1tUgelQgI"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "def remove_html_tags(text):\n",
        "    pattern = re.compile('<.*?>')\n",
        "    return pattern.sub(r'', text)\n",
        "\n",
        "def remove_url(text):\n",
        "    pattern = re.compile(r'https?://\\S+|www\\.\\S+')\n",
        "    return pattern.sub(r'', text)\n",
        "\n",
        "#exclude = \"!.,?\"\n",
        "def remove_punc(text):\n",
        "    return text.translate(str.maketrans('', '', exclude))\n",
        "\n",
        "stopwords = nltk.corpus.stopwords.words('english')\n",
        "def remove_stopwords(text):\n",
        "    return \" \".join([word for word in str(text).split() if word not in stopwords])\n",
        "\n",
        "from nltk.stem.porter import PorterStemmer\n",
        "ps = PorterStemmer()\n",
        "def stem_words(text):\n",
        "    return \" \".join([ps.stem(word) for word in text.split()])"
      ],
      "metadata": {
        "id": "bAzgkk6cVHcc"
      },
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df['text'] = df['text'].str.lower()\n",
        "\n",
        "df['text'] = df['text'].apply(remove_html_tags)\n",
        "\n",
        "df['text'] = df['text'].apply(remove_url)\n",
        "\n",
        "df['text'] = df['text'].apply(remove_punc)\n",
        "df['text'] = df['text'].apply(remove_stopwords)\n",
        "df['text'] = df['text'].apply(stem_words)"
      ],
      "metadata": {
        "id": "6dWUTvfVUrGH",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "d5d355a4-6b33-4447-f460-695bf78fba89"
      },
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-10-ae2a43c4bac6>:1: SettingWithCopyWarning: \n",
            "A value is trying to be set on a copy of a slice from a DataFrame.\n",
            "Try using .loc[row_indexer,col_indexer] = value instead\n",
            "\n",
            "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
            "  df['text'] = df['text'].str.lower()\n",
            "<ipython-input-10-ae2a43c4bac6>:3: SettingWithCopyWarning: \n",
            "A value is trying to be set on a copy of a slice from a DataFrame.\n",
            "Try using .loc[row_indexer,col_indexer] = value instead\n",
            "\n",
            "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
            "  df['text'] = df['text'].apply(remove_html_tags)\n",
            "<ipython-input-10-ae2a43c4bac6>:5: SettingWithCopyWarning: \n",
            "A value is trying to be set on a copy of a slice from a DataFrame.\n",
            "Try using .loc[row_indexer,col_indexer] = value instead\n",
            "\n",
            "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
            "  df['text'] = df['text'].apply(remove_url)\n",
            "<ipython-input-10-ae2a43c4bac6>:7: SettingWithCopyWarning: \n",
            "A value is trying to be set on a copy of a slice from a DataFrame.\n",
            "Try using .loc[row_indexer,col_indexer] = value instead\n",
            "\n",
            "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
            "  df['text'] = df['text'].apply(remove_punc)\n",
            "<ipython-input-10-ae2a43c4bac6>:8: SettingWithCopyWarning: \n",
            "A value is trying to be set on a copy of a slice from a DataFrame.\n",
            "Try using .loc[row_indexer,col_indexer] = value instead\n",
            "\n",
            "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
            "  df['text'] = df['text'].apply(remove_stopwords)\n",
            "<ipython-input-10-ae2a43c4bac6>:9: SettingWithCopyWarning: \n",
            "A value is trying to be set on a copy of a slice from a DataFrame.\n",
            "Try using .loc[row_indexer,col_indexer] = value instead\n",
            "\n",
            "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
            "  df['text'] = df['text'].apply(stem_words)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "df.head()"
      ],
      "metadata": {
        "id": "aXe4x2noU03H",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 206
        },
        "outputId": "6c8f6ca8-21c5-42c7-e5e6-72a0352d021a"
      },
      "execution_count": 73,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "        category                                               text\n",
              "0           tech  tv futur hand viewer home theatr system plasma...\n",
              "1       business  worldcom boss left book alon former worldcom b...\n",
              "2          sport  tiger wari farrel gambl leicest say rush make ...\n",
              "3          sport  yead face newcastl fa cup premiership side new...\n",
              "4  entertainment  ocean twelv raid box offic ocean twelv crime c..."
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-c085e5aa-19e7-411f-b54d-28eb00a16599\" class=\"colab-df-container\">\n",
              "    <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>category</th>\n",
              "      <th>text</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>tech</td>\n",
              "      <td>tv futur hand viewer home theatr system plasma...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>business</td>\n",
              "      <td>worldcom boss left book alon former worldcom b...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>sport</td>\n",
              "      <td>tiger wari farrel gambl leicest say rush make ...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>sport</td>\n",
              "      <td>yead face newcastl fa cup premiership side new...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>entertainment</td>\n",
              "      <td>ocean twelv raid box offic ocean twelv crime c...</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "    <div class=\"colab-df-buttons\">\n",
              "\n",
              "  <div class=\"colab-df-container\">\n",
              "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-c085e5aa-19e7-411f-b54d-28eb00a16599')\"\n",
              "            title=\"Convert this dataframe to an interactive table.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
              "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "\n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    .colab-df-buttons div {\n",
              "      margin-bottom: 4px;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "    <script>\n",
              "      const buttonEl =\n",
              "        document.querySelector('#df-c085e5aa-19e7-411f-b54d-28eb00a16599 button.colab-df-convert');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      async function convertToInteractive(key) {\n",
              "        const element = document.querySelector('#df-c085e5aa-19e7-411f-b54d-28eb00a16599');\n",
              "        const dataTable =\n",
              "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                    [key], {});\n",
              "        if (!dataTable) return;\n",
              "\n",
              "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "          + ' to learn more about interactive tables.';\n",
              "        element.innerHTML = '';\n",
              "        dataTable['output_type'] = 'display_data';\n",
              "        await google.colab.output.renderOutput(dataTable, element);\n",
              "        const docLink = document.createElement('div');\n",
              "        docLink.innerHTML = docLinkHtml;\n",
              "        element.appendChild(docLink);\n",
              "      }\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "\n",
              "<div id=\"df-c02ae72e-0179-4534-bbca-1c7bd81964d5\">\n",
              "  <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-c02ae72e-0179-4534-bbca-1c7bd81964d5')\"\n",
              "            title=\"Suggest charts\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "     width=\"24px\">\n",
              "    <g>\n",
              "        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n",
              "    </g>\n",
              "</svg>\n",
              "  </button>\n",
              "\n",
              "<style>\n",
              "  .colab-df-quickchart {\n",
              "      --bg-color: #E8F0FE;\n",
              "      --fill-color: #1967D2;\n",
              "      --hover-bg-color: #E2EBFA;\n",
              "      --hover-fill-color: #174EA6;\n",
              "      --disabled-fill-color: #AAA;\n",
              "      --disabled-bg-color: #DDD;\n",
              "  }\n",
              "\n",
              "  [theme=dark] .colab-df-quickchart {\n",
              "      --bg-color: #3B4455;\n",
              "      --fill-color: #D2E3FC;\n",
              "      --hover-bg-color: #434B5C;\n",
              "      --hover-fill-color: #FFFFFF;\n",
              "      --disabled-bg-color: #3B4455;\n",
              "      --disabled-fill-color: #666;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart {\n",
              "    background-color: var(--bg-color);\n",
              "    border: none;\n",
              "    border-radius: 50%;\n",
              "    cursor: pointer;\n",
              "    display: none;\n",
              "    fill: var(--fill-color);\n",
              "    height: 32px;\n",
              "    padding: 0;\n",
              "    width: 32px;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart:hover {\n",
              "    background-color: var(--hover-bg-color);\n",
              "    box-shadow: 0 1px 2px rgba(60, 64, 67, 0.3), 0 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "    fill: var(--button-hover-fill-color);\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart-complete:disabled,\n",
              "  .colab-df-quickchart-complete:disabled:hover {\n",
              "    background-color: var(--disabled-bg-color);\n",
              "    fill: var(--disabled-fill-color);\n",
              "    box-shadow: none;\n",
              "  }\n",
              "\n",
              "  .colab-df-spinner {\n",
              "    border: 2px solid var(--fill-color);\n",
              "    border-color: transparent;\n",
              "    border-bottom-color: var(--fill-color);\n",
              "    animation:\n",
              "      spin 1s steps(1) infinite;\n",
              "  }\n",
              "\n",
              "  @keyframes spin {\n",
              "    0% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "      border-left-color: var(--fill-color);\n",
              "    }\n",
              "    20% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    30% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    40% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    60% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    80% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "    90% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "  }\n",
              "</style>\n",
              "\n",
              "  <script>\n",
              "    async function quickchart(key) {\n",
              "      const quickchartButtonEl =\n",
              "        document.querySelector('#' + key + ' button');\n",
              "      quickchartButtonEl.disabled = true;  // To prevent multiple clicks.\n",
              "      quickchartButtonEl.classList.add('colab-df-spinner');\n",
              "      try {\n",
              "        const charts = await google.colab.kernel.invokeFunction(\n",
              "            'suggestCharts', [key], {});\n",
              "      } catch (error) {\n",
              "        console.error('Error during call to suggestCharts:', error);\n",
              "      }\n",
              "      quickchartButtonEl.classList.remove('colab-df-spinner');\n",
              "      quickchartButtonEl.classList.add('colab-df-quickchart-complete');\n",
              "    }\n",
              "    (() => {\n",
              "      let quickchartButtonEl =\n",
              "        document.querySelector('#df-c02ae72e-0179-4534-bbca-1c7bd81964d5 button');\n",
              "      quickchartButtonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "    })();\n",
              "  </script>\n",
              "</div>\n",
              "\n",
              "    </div>\n",
              "  </div>\n"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "dataframe",
              "variable_name": "df",
              "summary": "{\n  \"name\": \"df\",\n  \"rows\": 100,\n  \"fields\": [\n    {\n      \"column\": \"category\",\n      \"properties\": {\n        \"dtype\": \"category\",\n        \"num_unique_values\": 5,\n        \"samples\": [\n          \"business\",\n          \"politics\",\n          \"sport\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"text\",\n      \"properties\": {\n        \"dtype\": \"string\",\n        \"num_unique_values\": 99,\n        \"samples\": [\n          \"court reject 280bn tobacco case us govern claim accus countri biggest tobacco compani cover effect smoke thrown appeal court demand 280bn \\u00a3155bn file clinton administr 1999 reject 21 decis court washington found case could brought feder antiracket law among accus altria group rj reynold tobacco lorillard tobacco liggett group brown williamson case govern claim tobacco firm manipul nicotin level increas addict target teenag multibillion dollar advertis campaign lie danger smoke ignor research contrari prosecutor want cigarett firm surrend 280bn profit accumul past 50 year impos tougher rule market product court appeal district columbia rule us govern could sue firm legisl drawn counteract mafia infiltr busi tobacco compani deni illeg conspir promot smoke defraud public also say alreadi met mani govern demand landmark 206bn settlement reach 46 state 1998 share tobacco compani close higher rule altria rise 5 reynold show gain 45\",\n          \"labour target hardcor truant fresh crackdown persist truant england launch educ secretari ruth kelli serial truant make one 13 pupil previou initi brought 40 000 pupil back school sinc 1997 accord offici statist parent contract penalti notic fast track prosecut system use tackl stubborn problem thought nearli half million children skip school day tori say labour previou success regard issu came tackl easi part problem reduc authoris absenc parent permit take children school absenc often due famili holiday howev serial truant avoid classroom despit govern scheme cost \\u00a3885m miss class like becom involv crime well fail academ measur parent contract penalti notic adopt local educ author last term come forc remaind term one local educ author alon 800 parent warn would receiv penalti notic unless child attend improv tough stanc paid 24 issu attend improv 776 case truanci reduc 5 128 worst hit school govern behaviour improv programm equival 200 pupil back class sinc septemb new measur come top nation truanci sweep sixth take place monday polic educ welfar offic patrol problem hotspot pick truant return school held twice year addit routin local patrol previou countrywid sweep apprehend 31 000 pupil dodg school almost 14 000 case youngster accompani parent depart educ skill sourc said everi day school count clear form figur school local educ author seiz tool given improv school attend crack hard small number pupil account almost half nation truanci\",\n          \"oil rebound weather effect oil price recov asian trade tuesday fall new york milder winter weather across us winter temperatur stay rel high northern us barrel light crude end monday 133 4212 howev crude price rebound asia rise 4230 barrel februari deliveri london trade brent crude suspend public holiday price fell 3920 far east milder temperatur expect continu northern part us next day least analyst said price oil may fall even declin temporari weather achil heel market said abn amro analyst john bradi winter northeast eventu get anoth cold blast despit fall 12 barrel record high reach late octob price crude oil remain almost 30 higher yearago level price rose last week milit attack riyadh capit saudi arabia briefli renew fear suppli chain might broken world lead crude export market panick fear essenti evapor sinc followup said deborah white senior economist energi sg secur pari\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    }\n  ]\n}"
            }
          },
          "metadata": {},
          "execution_count": 73
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "df.isnull().sum()"
      ],
      "metadata": {
        "id": "1xFFxHFOq0C_",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 147
        },
        "outputId": "eb97469e-0e6c-4269-d390-04bb888bca57"
      },
      "execution_count": 74,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "category    0\n",
              "text        0\n",
              "dtype: int64"
            ],
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>0</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>category</th>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>text</th>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div><br><label><b>dtype:</b> int64</label>"
            ]
          },
          "metadata": {},
          "execution_count": 74
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **Feature Engineering**"
      ],
      "metadata": {
        "id": "zV6bPViYl3_Q"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Target Column Encoding**"
      ],
      "metadata": {
        "id": "JJozhru2MDY_"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "from sklearn.preprocessing import LabelEncoder\n",
        "\n",
        "X = df['text']\n",
        "Y = df['category']\n",
        "#print(X)\n",
        "#print(Y)\n",
        "\n",
        "encoder = LabelEncoder()\n",
        "Y = encoder.fit_transform(Y)\n",
        "\n",
        "#print(Y)\n",
        "\n",
        "X_train,X_test,y_train,y_test = train_test_split(X,Y,test_size=0.2,random_state=42)\n",
        "#print(X_train)\n",
        "#print(type(X_train))\n",
        "#print(type(y_train))\n",
        "#print(type(X_test))\n",
        "#print(type(y_test))"
      ],
      "metadata": {
        "id": "7ZflBvOgstHW"
      },
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Finetuning using Deep Learning**"
      ],
      "metadata": {
        "id": "aQMkc_XiUiFd"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "preprocessor = hub.KerasLayer(\"https://kaggle.com/models/tensorflow/bert/frameworks/TensorFlow2/variations/en-uncased-preprocess/versions/3\")\n",
        "encoder = hub.KerasLayer(\"https://www.kaggle.com/models/tensorflow/bert/frameworks/TensorFlow2/variations/en-uncased-l-12-h-768-a-12/versions/4\",trainable=True)\n",
        "\n",
        "\n",
        "text_input = tf.keras.layers.Input(shape=(), dtype=tf.string)\n",
        "#print (text_input)\n",
        "encoder_inputs = preprocessor(text_input)\n",
        "#print(encoder_inputs)\n",
        "outputs = encoder(encoder_inputs)\n",
        "#print(outputs)\n",
        "pooled_output = outputs[\"pooled_output\"]      # [batch_size, 768].\n",
        "#print(pooled_output)\n",
        "\n",
        "drop_out = tf.keras.layers.Dropout(0.2,name='dropout')(pooled_output)\n",
        "output = tf.keras.layers.Dense(5,activation='softmax',name='output')(drop_out)\n",
        "\n",
        "model=tf.keras.Model(inputs=[text_input],outputs=[output])\n",
        "\n"
      ],
      "metadata": {
        "id": "xWZDBNbMYWvM"
      },
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Compile the model\n",
        "# Use 'categorical_crossentropy' for multi-class classification\n",
        "model.compile(optimizer='adam', loss='categorical_crossentropy', metrics=['accuracy'])\n",
        "\n",
        "# Convert y_train to one-hot encoding using tf.keras.utils.to_categorical\n",
        "from tensorflow.keras.utils import to_categorical\n",
        "y_train = to_categorical(y_train, num_classes=5)\n",
        "\n",
        "history = model.fit(X_train, y_train, epochs=3, validation_split=0.1)"
      ],
      "metadata": {
        "id": "WPGTtC4NYona",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "54629611-83d4-42c7-9613-e27cab45604b"
      },
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/3\n",
            "3/3 [==============================] - 158s 36s/step - loss: 1.7390 - accuracy: 0.2778 - val_loss: 1.4835 - val_accuracy: 0.1250\n",
            "Epoch 2/3\n",
            "3/3 [==============================] - 132s 41s/step - loss: 1.9603 - accuracy: 0.2500 - val_loss: 1.8505 - val_accuracy: 0.2500\n",
            "Epoch 3/3\n",
            "3/3 [==============================] - 117s 34s/step - loss: 2.9082 - accuracy: 0.1389 - val_loss: 1.9977 - val_accuracy: 0.2500\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Extract embeddings from the fine-tuned BERT model\n",
        "def extract_embeddings(text_data):\n",
        "    return model.predict(text_data)\n",
        "\n",
        "# Get the embeddings for both training and testing sets\n",
        "X_train_embeddings = extract_embeddings(X_train)\n",
        "X_test_embeddings = extract_embeddings(X_test)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "GhOHfPgg-AMC",
        "outputId": "bd2376fc-ba92-4316-ddf5-8be75c448b8d"
      },
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "3/3 [==============================] - 43s 12s/step\n",
            "1/1 [==============================] - 11s 11s/step\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.ensemble import RandomForestClassifier\n",
        "from sklearn.metrics import accuracy_score\n",
        "\n",
        "# Initialize the Random Forest classifier\n",
        "rf = RandomForestClassifier(n_estimators=100, random_state=42)\n",
        "\n",
        "# Train the Random Forest model on the BERT embeddings\n",
        "rf.fit(X_train_embeddings, y_train.argmax(axis=1))  # y_train is one-hot encoded, use argmax to get class labels\n",
        "\n",
        "# Make predictions on the test set\n",
        "y_pred = rf.predict(X_test_embeddings)\n",
        "\n",
        "# Evaluate the Random Forest model\n",
        "# Remove argmax for y_test as it is already in the correct format\n",
        "accuracy = accuracy_score(y_test, y_pred)\n",
        "print(f\"Random Forest model accuracy: {accuracy:.4f}\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "uRkO9U74-HOd",
        "outputId": "fdbb744d-2e62-4d65-8a67-a276d4d1da95"
      },
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Random Forest model accuracy: 0.4500\n"
          ]
        }
      ]
    }
  ]
}